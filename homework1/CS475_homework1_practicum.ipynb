{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "11d61287",
      "metadata": {
        "id": "11d61287"
      },
      "source": [
        "# Homework 1 Practicum\n",
        "### Version 1.0 (September 06, 2024)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "61f55ee7",
      "metadata": {
        "id": "61f55ee7"
      },
      "source": [
        "<font color='blue'>TODO:</font> NAME (JHED)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0cab3159",
      "metadata": {
        "id": "0cab3159"
      },
      "source": [
        "**Instructions:**\n",
        "This notebook is intended to guide you through implement ID3 algorithm. Please answer all questions in this notebook (you will see <font color='blue'>TODO</font> annotations for where to include your answers). At the beginning of each part, we will bullet the expected deliverables for you to complete. All questions can be answered in 1-4 sentences, unless otherwise noted.\n",
        "\n",
        "Please <font color='blue'>make a copy of this notebook in your own drive</font> before you make any edits. You can do so through File -> Save a copy in Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4e0c924c",
      "metadata": {
        "id": "4e0c924c",
        "tags": []
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c535ffa4",
      "metadata": {
        "id": "c535ffa4"
      },
      "source": [
        "# Part I: Tennis dataset\n",
        "\n",
        "Things to do in this part:  \n",
        "1. Fill in the missing code in the DecisionTree Class.\n",
        "1. Implement the evaluation function in the DecisionTree Class.\n",
        "  \n",
        "  \n",
        "\n",
        "In this part, we will work with a toy dataset that records decisions on whether to play tennis depending on weather conditions. We will implement a (binary) decision tree classifier (ID3 algorithm) to predict whether to play tennis based on the weather conditions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "700508ec",
      "metadata": {
        "id": "700508ec",
        "outputId": "0d4f1ba0-f69e-4b49-9623-b9063c5dd7e3"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Outlook</th>\n",
              "      <th>Temperature</th>\n",
              "      <th>Humidity</th>\n",
              "      <th>Wind</th>\n",
              "      <th>Play</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Sunny</td>\n",
              "      <td>Hot</td>\n",
              "      <td>High</td>\n",
              "      <td>Weak</td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Sunny</td>\n",
              "      <td>Hot</td>\n",
              "      <td>High</td>\n",
              "      <td>Strong</td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Overcast</td>\n",
              "      <td>Hot</td>\n",
              "      <td>High</td>\n",
              "      <td>Weak</td>\n",
              "      <td>Yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Rain</td>\n",
              "      <td>Mild</td>\n",
              "      <td>High</td>\n",
              "      <td>Weak</td>\n",
              "      <td>Yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Rain</td>\n",
              "      <td>Cool</td>\n",
              "      <td>Normal</td>\n",
              "      <td>Weak</td>\n",
              "      <td>Yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Rain</td>\n",
              "      <td>Cool</td>\n",
              "      <td>Normal</td>\n",
              "      <td>Strong</td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Overcast</td>\n",
              "      <td>Cool</td>\n",
              "      <td>Normal</td>\n",
              "      <td>Strong</td>\n",
              "      <td>Yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Sunny</td>\n",
              "      <td>Mild</td>\n",
              "      <td>High</td>\n",
              "      <td>Weak</td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Sunny</td>\n",
              "      <td>Cool</td>\n",
              "      <td>Normal</td>\n",
              "      <td>Weak</td>\n",
              "      <td>Yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Rain</td>\n",
              "      <td>Mild</td>\n",
              "      <td>Normal</td>\n",
              "      <td>Weak</td>\n",
              "      <td>Yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>Sunny</td>\n",
              "      <td>Mild</td>\n",
              "      <td>Normal</td>\n",
              "      <td>Strong</td>\n",
              "      <td>Yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>Overcast</td>\n",
              "      <td>Mild</td>\n",
              "      <td>High</td>\n",
              "      <td>Strong</td>\n",
              "      <td>Yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>Overcast</td>\n",
              "      <td>Hot</td>\n",
              "      <td>Normal</td>\n",
              "      <td>Weak</td>\n",
              "      <td>Yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>Rain</td>\n",
              "      <td>Mild</td>\n",
              "      <td>High</td>\n",
              "      <td>Strong</td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     Outlook Temperature Humidity    Wind Play\n",
              "0      Sunny         Hot     High    Weak   No\n",
              "1      Sunny         Hot     High  Strong   No\n",
              "2   Overcast         Hot     High    Weak  Yes\n",
              "3       Rain        Mild     High    Weak  Yes\n",
              "4       Rain        Cool   Normal    Weak  Yes\n",
              "5       Rain        Cool   Normal  Strong   No\n",
              "6   Overcast        Cool   Normal  Strong  Yes\n",
              "7      Sunny        Mild     High    Weak   No\n",
              "8      Sunny        Cool   Normal    Weak  Yes\n",
              "9       Rain        Mild   Normal    Weak  Yes\n",
              "10     Sunny        Mild   Normal  Strong  Yes\n",
              "11  Overcast        Mild     High  Strong  Yes\n",
              "12  Overcast         Hot   Normal    Weak  Yes\n",
              "13      Rain        Mild     High  Strong   No"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data = [['Sunny', 'Hot', 'High', 'Weak', 'No'],\n",
        "       ['Sunny', 'Hot', 'High', 'Strong', 'No'],\n",
        "       ['Overcast', 'Hot', 'High', 'Weak', 'Yes'],\n",
        "       ['Rain', 'Mild', 'High', 'Weak', 'Yes'],\n",
        "       ['Rain', 'Cool', 'Normal', 'Weak', 'Yes'],\n",
        "       ['Rain', 'Cool', 'Normal', 'Strong', 'No'],\n",
        "       ['Overcast', 'Cool', 'Normal', 'Strong', 'Yes'],\n",
        "       ['Sunny', 'Mild', 'High', 'Weak', 'No'],\n",
        "       ['Sunny', 'Cool', 'Normal', 'Weak', 'Yes'],\n",
        "       ['Rain', 'Mild', 'Normal', 'Weak', 'Yes'],\n",
        "       ['Sunny', 'Mild', 'Normal', 'Strong', 'Yes'],\n",
        "       ['Overcast', 'Mild', 'High', 'Strong', 'Yes'],\n",
        "       ['Overcast', 'Hot', 'Normal', 'Weak', 'Yes'],\n",
        "       ['Rain', 'Mild', 'High', 'Strong', 'No']]\n",
        "colums = ['Outlook', 'Temperature', 'Humidity', 'Wind', 'Play']\n",
        "dataset = pd.DataFrame(data, columns = colums)\n",
        "dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3a775994",
      "metadata": {
        "id": "3a775994"
      },
      "source": [
        "We provide the class TreeNode that represents a node in the decision tree. Each node has a feature with the corresponding splitting value, and two children nodes. The class TreeBase provides the basic structure of a decision tree, and the class DecisionTree inherits from TreeBase, which you need to complete the missing parts."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d100ad77",
      "metadata": {
        "id": "d100ad77"
      },
      "outputs": [],
      "source": [
        "class TreeNode(object): # Do not modify this class\n",
        "    '''\n",
        "    A node class for a decision tree.\n",
        "    '''\n",
        "    def __init__(self, feature=None, value=None, left=None, right=None, label=None):\n",
        "        self.feature = feature # feature to split on\n",
        "        self.value = value # value used for splitting\n",
        "        self.left = left # left child\n",
        "        self.right = right # right child\n",
        "        self.label = label # label for the node"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "28c197fc",
      "metadata": {
        "id": "28c197fc"
      },
      "source": [
        "The class TreeBase give you the overall structure of building a decision tree recursively (`build_tree` function), which following these essential steps:\n",
        "- Create a root of the tree, and split the dataset based on the feature that gives the most information gain.\n",
        "- Recursively build the left and right subtrees.\n",
        "- Stop the recursion when the stopping criteria are met."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6c3a12c5",
      "metadata": {
        "id": "6c3a12c5"
      },
      "outputs": [],
      "source": [
        "class TreeBase(object): # Do not modify this class\n",
        "    def __init__(self, data, label, max_depth=5):\n",
        "        '''\n",
        "        Constructor\n",
        "        Parameters:\n",
        "            data: DataFrame, the data for the tree\n",
        "            label: str, the label of the target\n",
        "            max_depth: int, the maximum depth of the tree\n",
        "        '''\n",
        "        self.data = data\n",
        "        self.root = None\n",
        "        self.max_depth = max_depth\n",
        "        self.label = label\n",
        "        self.features = data.columns.drop(label)\n",
        "\n",
        "    def select_best_feature(self, data, features):\n",
        "        '''\n",
        "        Select the feature with the highest information gain\n",
        "        Parameters:\n",
        "            data: DataFrame\n",
        "            features: list of features\n",
        "        Returns:\n",
        "            best_feature: str\n",
        "            best_value: str\n",
        "        '''\n",
        "        best_gain = 0\n",
        "\n",
        "        for feature in features: #Iterate over all features\n",
        "            values = data[feature].unique() #Get all unique values of the feature\n",
        "            for value in values: #Iterate over all values\n",
        "                gain = self.information_gain(data, feature, value) #Calculate the information gain\n",
        "                if gain > best_gain:\n",
        "                    best_gain = gain\n",
        "                    best_feature = feature\n",
        "                    best_value = value\n",
        "\n",
        "        return best_feature, best_value\n",
        "\n",
        "    def entropy(self, data):\n",
        "        raise NotImplementedError\n",
        "\n",
        "    def information_gain(self, data, feature, value):\n",
        "        raise NotImplementedError\n",
        "\n",
        "    def predict(self, data_point):\n",
        "        '''\n",
        "        Predict the label for a single instance\n",
        "        Parameters:\n",
        "            data_point: pandas Series, with keys being the feature names\n",
        "        Returns:\n",
        "            label: the label of the instance\n",
        "        '''\n",
        "        node = self.root\n",
        "        label = None\n",
        "        while True:\n",
        "            if node.label is not None: #Leaf node\n",
        "                label = node.label\n",
        "                break\n",
        "            if type(node.value) == str: #Categorical feature\n",
        "                go_left = data_point[node.feature] == node.value\n",
        "            else: #Numerical feature\n",
        "                go_left = data_point[node.feature] < node.value\n",
        "\n",
        "            if go_left:\n",
        "                node = node.left\n",
        "            else:\n",
        "                node = node.right\n",
        "        return label\n",
        "\n",
        "    def fit(self):\n",
        "        self.root = self.build_tree(TreeNode(), self.data, self.features, 0) #Build the tree\n",
        "\n",
        "    def build_tree(self, node, data, features, depth):\n",
        "        '''\n",
        "        Recursively build the decision tree\n",
        "        Parameters:\n",
        "            node: TreeNode, current node to be split\n",
        "            data: DataFrame, the data for the tree\n",
        "            features: list of features\n",
        "            depth: int, the current depth of the tree\n",
        "        Returns:\n",
        "            node: TreeNode, the root of the built tree\n",
        "        '''\n",
        "\n",
        "        #Stop if the entropy is 0, or the depth >= max_depth, or all data points has the same feature value.\n",
        "        stop = np.isclose(self.entropy(data), 0) or \\\n",
        "                 depth >= self.max_depth or \\\n",
        "                 (data.values[0] == data.values).all()\n",
        "        if stop:\n",
        "            node = TreeNode()\n",
        "            node.label = data[self.label].mode()[0] #Get the most common label, only set label for leaf nodes\n",
        "            return node\n",
        "\n",
        "        feature, value = self.select_best_feature(data, features)\n",
        "        node = TreeNode(feature=feature, value=value)\n",
        "        if type(value) == str: #Categorical feature\n",
        "            left_data, right_data = data[data[feature] == value], data[data[feature] != value]\n",
        "        else: #Numerical feature\n",
        "            left_data, right_data = data[data[feature] < value], data[data[feature] >= value]\n",
        "\n",
        "        node.left = self.build_tree(node.left, left_data, features, depth + 1)\n",
        "        node.right = self.build_tree(node.right, right_data, features, depth + 1)\n",
        "        return node\n",
        "\n",
        "    def print_tree(self):\n",
        "        '''\n",
        "        Print the tree\n",
        "        Parameters:\n",
        "            node: TreeNode, the current node\n",
        "            depth: int, the current depth of the tree\n",
        "        '''\n",
        "        self._print_tree(self.root, 0)\n",
        "\n",
        "    def _print_tree(self, node, depth):\n",
        "        '''\n",
        "        Recursively print the tree\n",
        "        Parameters:\n",
        "            node: TreeNode, the current node\n",
        "            depth: int, the current depth of the tree\n",
        "        '''\n",
        "        if node is None:\n",
        "            return\n",
        "        if node.label is not None:\n",
        "            print(\" \" * depth, node.label)\n",
        "        else:\n",
        "            if type(node.value) == str:\n",
        "                print(\" \" * depth, node.feature, \"=\", node.value)\n",
        "            else:\n",
        "                print(\" \" * depth, node.feature, \"<\", node.value)\n",
        "            self._print_tree(node.left, depth + 1)\n",
        "            self._print_tree(node.right, depth + 1)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b978a829",
      "metadata": {
        "id": "b978a829"
      },
      "source": [
        "You will need to **provide the missing code** in the DecisionTree class below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "332fb2d6",
      "metadata": {
        "id": "332fb2d6"
      },
      "outputs": [],
      "source": [
        "class DecisionTree(TreeBase):\n",
        "    '''\n",
        "    Binary decision tree class, inherits from TreeBase\n",
        "    '''\n",
        "    def __init__(self, data, label, max_depth=5):\n",
        "        super(DecisionTree, self).__init__(data, label, max_depth)\n",
        "\n",
        "    def entropy(self, data):\n",
        "        '''\n",
        "        Calculate the entropy of the data\n",
        "        Parameters:\n",
        "            data: DataFrame\n",
        "        Returns:\n",
        "            the entropy of the data\n",
        "        '''\n",
        "        # TODO: ...WRITE YOUR CODE HERE...\n",
        "        pass\n",
        "\n",
        "    def information_gain(self, data, feature, value):\n",
        "        '''\n",
        "        Calculate the information gain\n",
        "        Parameters:\n",
        "            data: DataFrame\n",
        "            feature: the feature to split\n",
        "            vavlue: the value of the feature\n",
        "        Returns:\n",
        "            the information gain\n",
        "\n",
        "        '''\n",
        "        # TODO: ...WRITE YOUR CODE HERE...\n",
        "        pass"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ff2934cc",
      "metadata": {
        "id": "ff2934cc"
      },
      "source": [
        "We provide the code to test the decision tree on the tennis dataset. You can add more tests to check your implementation. We will not grade your additional tests, but we encourage you to do so to ensure your implementation is correct."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c60d121e",
      "metadata": {
        "id": "c60d121e"
      },
      "outputs": [],
      "source": [
        "dt = DecisionTree(dataset, 'Play', 5)\n",
        "data_test1 = dataset.iloc[:6]\n",
        "assert np.isclose(dt.entropy(data_test1), 1.0) # Test entropy implementation\n",
        "dt.fit() # Test build the tree and make sure there is no error"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f595d461",
      "metadata": {
        "id": "f595d461"
      },
      "outputs": [],
      "source": [
        "dt.print_tree() # Print the tree"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3af9bf33",
      "metadata": {
        "id": "3af9bf33"
      },
      "outputs": [],
      "source": [
        "sample = dataset.iloc[0]\n",
        "print(sample)\n",
        "print('----------')\n",
        "print('prediction:', dt.predict(sample)) # Test predict function"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "65f3af6c",
      "metadata": {
        "id": "65f3af6c"
      },
      "source": [
        "Next, you will need to provide the code for evaluating the tree. The function take a tree model, and a dataset then output the accuracy of the decision tree on the dataset. The accuracy is defined as the number of correct predictions divided by the total number of predictions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4f1ed42a",
      "metadata": {
        "id": "4f1ed42a"
      },
      "outputs": [],
      "source": [
        "def evaluate(dt: TreeBase, dataset: pd.DataFrame):\n",
        "    '''\n",
        "    Evaluate the decision tree\n",
        "    Parameters:\n",
        "        dt: DecisionTree\n",
        "        dataset: DataFrame\n",
        "    Returns:\n",
        "        accuracy: the accuracy of the model on the dataset\n",
        "    '''\n",
        "    # TODO: ...WRITE YOUR CODE HERE...\n",
        "    pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e57e1088",
      "metadata": {
        "id": "e57e1088"
      },
      "outputs": [],
      "source": [
        "# test evaluate function\n",
        "print('accuracy:', evaluate(dt, dataset)) # Test evaluate function"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b27d4480",
      "metadata": {
        "id": "b27d4480"
      },
      "source": [
        "# Part II: The effect of tree complexity on the performance\n",
        "\n",
        "Things to do in this part:\n",
        "1. Update your DecisionTree class to handle numerical features.\n",
        "1. Provide the code for training and evaluating the decision tree with various tree depths.\n",
        "1. Plot the train and test accuracy.\n",
        "1. Answer discussion questions.\n",
        "\n",
        "\n",
        "Unlike the tennis dataset, which contains only categorical data, this part will involve working with numerical data. If you haven't already, modify your DecisionTree code to handle both categorical and numerical features. The code below generates a dataset of 1,000 samples with binary class labels. As in the previous section, we will store the dataset in a pandas DataFrame."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f5754a84",
      "metadata": {
        "id": "f5754a84",
        "outputId": "0936b44b-daaa-4291-d297-00a10c8ae3ec"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>feature_0</th>\n",
              "      <th>feature_1</th>\n",
              "      <th>feature_2</th>\n",
              "      <th>feature_3</th>\n",
              "      <th>feature_4</th>\n",
              "      <th>feature_5</th>\n",
              "      <th>feature_6</th>\n",
              "      <th>feature_7</th>\n",
              "      <th>feature_8</th>\n",
              "      <th>feature_9</th>\n",
              "      <th>...</th>\n",
              "      <th>feature_11</th>\n",
              "      <th>feature_12</th>\n",
              "      <th>feature_13</th>\n",
              "      <th>feature_14</th>\n",
              "      <th>feature_15</th>\n",
              "      <th>feature_16</th>\n",
              "      <th>feature_17</th>\n",
              "      <th>feature_18</th>\n",
              "      <th>feature_19</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-0.272427</td>\n",
              "      <td>-0.029398</td>\n",
              "      <td>-0.636882</td>\n",
              "      <td>1.520092</td>\n",
              "      <td>-0.239273</td>\n",
              "      <td>1.569953</td>\n",
              "      <td>0.207139</td>\n",
              "      <td>-0.751345</td>\n",
              "      <td>-0.310397</td>\n",
              "      <td>-0.693804</td>\n",
              "      <td>...</td>\n",
              "      <td>-1.482397</td>\n",
              "      <td>0.884843</td>\n",
              "      <td>0.131119</td>\n",
              "      <td>-1.607711</td>\n",
              "      <td>2.051247</td>\n",
              "      <td>-1.954593</td>\n",
              "      <td>-0.099314</td>\n",
              "      <td>-0.527984</td>\n",
              "      <td>-1.569390</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.603702</td>\n",
              "      <td>-0.758917</td>\n",
              "      <td>-1.073091</td>\n",
              "      <td>0.405850</td>\n",
              "      <td>-1.308684</td>\n",
              "      <td>-0.445018</td>\n",
              "      <td>-0.848905</td>\n",
              "      <td>0.906784</td>\n",
              "      <td>0.913607</td>\n",
              "      <td>0.690701</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.866448</td>\n",
              "      <td>-0.797485</td>\n",
              "      <td>-0.069852</td>\n",
              "      <td>2.329718</td>\n",
              "      <td>0.380520</td>\n",
              "      <td>0.459637</td>\n",
              "      <td>0.142688</td>\n",
              "      <td>-0.214368</td>\n",
              "      <td>-0.125819</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.725821</td>\n",
              "      <td>-0.498031</td>\n",
              "      <td>0.551256</td>\n",
              "      <td>0.612412</td>\n",
              "      <td>1.700972</td>\n",
              "      <td>0.462312</td>\n",
              "      <td>-1.139286</td>\n",
              "      <td>-0.370698</td>\n",
              "      <td>-0.271115</td>\n",
              "      <td>0.305701</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.233880</td>\n",
              "      <td>-0.201946</td>\n",
              "      <td>0.550813</td>\n",
              "      <td>0.721858</td>\n",
              "      <td>-1.250026</td>\n",
              "      <td>0.349293</td>\n",
              "      <td>0.551437</td>\n",
              "      <td>-0.387667</td>\n",
              "      <td>0.923033</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.946618</td>\n",
              "      <td>0.029895</td>\n",
              "      <td>-0.335516</td>\n",
              "      <td>-0.216419</td>\n",
              "      <td>-1.119250</td>\n",
              "      <td>-0.057604</td>\n",
              "      <td>0.255977</td>\n",
              "      <td>-0.363176</td>\n",
              "      <td>0.369926</td>\n",
              "      <td>-0.270270</td>\n",
              "      <td>...</td>\n",
              "      <td>0.915824</td>\n",
              "      <td>-0.778309</td>\n",
              "      <td>-0.136422</td>\n",
              "      <td>-0.011394</td>\n",
              "      <td>-0.443429</td>\n",
              "      <td>0.934655</td>\n",
              "      <td>1.612868</td>\n",
              "      <td>0.033045</td>\n",
              "      <td>-0.140276</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-0.249894</td>\n",
              "      <td>-0.725025</td>\n",
              "      <td>-0.426571</td>\n",
              "      <td>-0.404639</td>\n",
              "      <td>1.355805</td>\n",
              "      <td>0.683565</td>\n",
              "      <td>-0.389404</td>\n",
              "      <td>0.558695</td>\n",
              "      <td>0.280236</td>\n",
              "      <td>0.384209</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.907327</td>\n",
              "      <td>-0.892773</td>\n",
              "      <td>-1.224387</td>\n",
              "      <td>1.039595</td>\n",
              "      <td>1.734042</td>\n",
              "      <td>0.292149</td>\n",
              "      <td>0.107760</td>\n",
              "      <td>-0.567810</td>\n",
              "      <td>-1.197958</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 21 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   feature_0  feature_1  feature_2  feature_3  feature_4  feature_5  \\\n",
              "0  -0.272427  -0.029398  -0.636882   1.520092  -0.239273   1.569953   \n",
              "1   1.603702  -0.758917  -1.073091   0.405850  -1.308684  -0.445018   \n",
              "2   0.725821  -0.498031   0.551256   0.612412   1.700972   0.462312   \n",
              "3   0.946618   0.029895  -0.335516  -0.216419  -1.119250  -0.057604   \n",
              "4  -0.249894  -0.725025  -0.426571  -0.404639   1.355805   0.683565   \n",
              "\n",
              "   feature_6  feature_7  feature_8  feature_9  ...  feature_11  feature_12  \\\n",
              "0   0.207139  -0.751345  -0.310397  -0.693804  ...   -1.482397    0.884843   \n",
              "1  -0.848905   0.906784   0.913607   0.690701  ...   -0.866448   -0.797485   \n",
              "2  -1.139286  -0.370698  -0.271115   0.305701  ...   -0.233880   -0.201946   \n",
              "3   0.255977  -0.363176   0.369926  -0.270270  ...    0.915824   -0.778309   \n",
              "4  -0.389404   0.558695   0.280236   0.384209  ...   -0.907327   -0.892773   \n",
              "\n",
              "   feature_13  feature_14  feature_15  feature_16  feature_17  feature_18  \\\n",
              "0    0.131119   -1.607711    2.051247   -1.954593   -0.099314   -0.527984   \n",
              "1   -0.069852    2.329718    0.380520    0.459637    0.142688   -0.214368   \n",
              "2    0.550813    0.721858   -1.250026    0.349293    0.551437   -0.387667   \n",
              "3   -0.136422   -0.011394   -0.443429    0.934655    1.612868    0.033045   \n",
              "4   -1.224387    1.039595    1.734042    0.292149    0.107760   -0.567810   \n",
              "\n",
              "   feature_19  label  \n",
              "0   -1.569390    1.0  \n",
              "1   -0.125819    0.0  \n",
              "2    0.923033    1.0  \n",
              "3   -0.140276    1.0  \n",
              "4   -1.197958    1.0  \n",
              "\n",
              "[5 rows x 21 columns]"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Don't modify this cell, we will use this code to generate synthetic data\n",
        "X, y = make_classification(n_samples=1000, n_features=20, n_classes=2, random_state=42)\n",
        "# Split data into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.7, random_state=42)\n",
        "# Create a pandas DataFrame for the train/test data\n",
        "columns = ['feature_' + str(i) for i in range(X_train.shape[1])] + ['label']\n",
        "df_train = pd.DataFrame(np.column_stack((X_train, y_train)), columns=columns)\n",
        "df_test = pd.DataFrame(np.column_stack((X_test, y_test)), columns=columns)\n",
        "df_train.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5c2b6c03",
      "metadata": {
        "id": "5c2b6c03"
      },
      "outputs": [],
      "source": [
        "# test fitting the decision tree\n",
        "dt = DecisionTree(df_train, 'label', 0)\n",
        "dt.fit()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ae783b7b",
      "metadata": {
        "id": "ae783b7b"
      },
      "outputs": [],
      "source": [
        "# test evaluate function\n",
        "train_acc_value, test_acc_value = evaluate(dt, df_train), evaluate(dt, df_test)\n",
        "print('Train accuracy:', train_acc_value)\n",
        "print('Test accuracy:', test_acc_value)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d8f8e40c",
      "metadata": {
        "id": "d8f8e40c"
      },
      "source": [
        "Now, we will try to understand the effect of the complexity of the tree on the performance. We will use the depth of the tree as a measure of complexity. We will train the decision tree with different depths and evaluate the performance on the training and testing datasets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8bd3cf21",
      "metadata": {
        "id": "8bd3cf21"
      },
      "outputs": [],
      "source": [
        "max_depth = 10 #you can vary the depth, the larger the depth, the longer it will take to train. This is just our recommended number\n",
        "train_acc, test_acc = [], [] #store the training/test accuracy for each tree depth\n",
        "for tree_depth in range(max_depth + 1):\n",
        "    # TODO: ...WRITE YOUR CODE HERE...\n",
        "    # Fit the decision tree for each tree depth and evaluate the accuracy of on the training and test data\n",
        "    pass"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "18ec1e38",
      "metadata": {
        "id": "18ec1e38"
      },
      "source": [
        "Plot the train and test accuracy with the corresponding depth of the tree. The x axis should be the maximum depth of the tree, and the y axis should be the accuracy. You should have two plots, one for the training accuracy and one for the testing accuracy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "11ed2264",
      "metadata": {
        "id": "11ed2264"
      },
      "outputs": [],
      "source": [
        "# TODO: ...WRITE YOUR CODE HERE...\n",
        "# write the code to plot the train and test accuracy for each tree depth"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e9cfdb51",
      "metadata": {
        "id": "e9cfdb51"
      },
      "source": [
        "#### Discussion questions:\n",
        "\n",
        "What do you observe from the plot? Discuss your findings based on the train and test accuracy when increasing the depth of the tree."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "639fd610",
      "metadata": {
        "id": "639fd610"
      },
      "source": [
        "<font color='blue'>\n",
        "    TODO: replace this cell with your answer\n",
        "</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c0e7a706",
      "metadata": {
        "id": "c0e7a706"
      },
      "source": [
        "## Feedback\n",
        "\n",
        "Please provide us with some feedback on how long each section or this homework overall took you. Any other feedback is also welcomed."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dcefedb6",
      "metadata": {
        "id": "dcefedb6"
      },
      "source": [
        "## Submit\n",
        "Great work! You're all done.\n",
        "\n",
        "Make sure to submit this Python notebook. See the homework writeup for directions."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
