{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "11d61287",
      "metadata": {
        "id": "11d61287"
      },
      "source": [
        "# Homework 1 Practicum\n",
        "### Version 1.0 (September 06, 2024)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "61f55ee7",
      "metadata": {
        "id": "61f55ee7"
      },
      "source": [
        "<font color='blue'>TODO:</font> Trevor Black (tblack20)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0cab3159",
      "metadata": {
        "id": "0cab3159"
      },
      "source": [
        "**Instructions:**\n",
        "This notebook is intended to guide you through implement ID3 algorithm. Please answer all questions in this notebook (you will see <font color='blue'>TODO</font> annotations for where to include your answers). At the beginning of each part, we will bullet the expected deliverables for you to complete. All questions can be answered in 1-4 sentences, unless otherwise noted.\n",
        "\n",
        "Please <font color='blue'>make a copy of this notebook in your own drive</font> before you make any edits. You can do so through File -> Save a copy in Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 138,
      "id": "4e0c924c",
      "metadata": {
        "id": "4e0c924c",
        "tags": []
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c535ffa4",
      "metadata": {
        "id": "c535ffa4"
      },
      "source": [
        "# Part I: Tennis dataset\n",
        "\n",
        "Things to do in this part:  \n",
        "1. Fill in the missing code in the DecisionTree Class.\n",
        "1. Implement the evaluation function in the DecisionTree Class.\n",
        "  \n",
        "  \n",
        "\n",
        "In this part, we will work with a toy dataset that records decisions on whether to play tennis depending on weather conditions. We will implement a (binary) decision tree classifier (ID3 algorithm) to predict whether to play tennis based on the weather conditions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 139,
      "id": "700508ec",
      "metadata": {
        "id": "700508ec",
        "outputId": "0d4f1ba0-f69e-4b49-9623-b9063c5dd7e3"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Outlook</th>\n",
              "      <th>Temperature</th>\n",
              "      <th>Humidity</th>\n",
              "      <th>Wind</th>\n",
              "      <th>Play</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Sunny</td>\n",
              "      <td>Hot</td>\n",
              "      <td>High</td>\n",
              "      <td>Weak</td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Sunny</td>\n",
              "      <td>Hot</td>\n",
              "      <td>High</td>\n",
              "      <td>Strong</td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Overcast</td>\n",
              "      <td>Hot</td>\n",
              "      <td>High</td>\n",
              "      <td>Weak</td>\n",
              "      <td>Yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Rain</td>\n",
              "      <td>Mild</td>\n",
              "      <td>High</td>\n",
              "      <td>Weak</td>\n",
              "      <td>Yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Rain</td>\n",
              "      <td>Cool</td>\n",
              "      <td>Normal</td>\n",
              "      <td>Weak</td>\n",
              "      <td>Yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Rain</td>\n",
              "      <td>Cool</td>\n",
              "      <td>Normal</td>\n",
              "      <td>Strong</td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Overcast</td>\n",
              "      <td>Cool</td>\n",
              "      <td>Normal</td>\n",
              "      <td>Strong</td>\n",
              "      <td>Yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Sunny</td>\n",
              "      <td>Mild</td>\n",
              "      <td>High</td>\n",
              "      <td>Weak</td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Sunny</td>\n",
              "      <td>Cool</td>\n",
              "      <td>Normal</td>\n",
              "      <td>Weak</td>\n",
              "      <td>Yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Rain</td>\n",
              "      <td>Mild</td>\n",
              "      <td>Normal</td>\n",
              "      <td>Weak</td>\n",
              "      <td>Yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>Sunny</td>\n",
              "      <td>Mild</td>\n",
              "      <td>Normal</td>\n",
              "      <td>Strong</td>\n",
              "      <td>Yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>Overcast</td>\n",
              "      <td>Mild</td>\n",
              "      <td>High</td>\n",
              "      <td>Strong</td>\n",
              "      <td>Yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>Overcast</td>\n",
              "      <td>Hot</td>\n",
              "      <td>Normal</td>\n",
              "      <td>Weak</td>\n",
              "      <td>Yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>Rain</td>\n",
              "      <td>Mild</td>\n",
              "      <td>High</td>\n",
              "      <td>Strong</td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     Outlook Temperature Humidity    Wind Play\n",
              "0      Sunny         Hot     High    Weak   No\n",
              "1      Sunny         Hot     High  Strong   No\n",
              "2   Overcast         Hot     High    Weak  Yes\n",
              "3       Rain        Mild     High    Weak  Yes\n",
              "4       Rain        Cool   Normal    Weak  Yes\n",
              "5       Rain        Cool   Normal  Strong   No\n",
              "6   Overcast        Cool   Normal  Strong  Yes\n",
              "7      Sunny        Mild     High    Weak   No\n",
              "8      Sunny        Cool   Normal    Weak  Yes\n",
              "9       Rain        Mild   Normal    Weak  Yes\n",
              "10     Sunny        Mild   Normal  Strong  Yes\n",
              "11  Overcast        Mild     High  Strong  Yes\n",
              "12  Overcast         Hot   Normal    Weak  Yes\n",
              "13      Rain        Mild     High  Strong   No"
            ]
          },
          "execution_count": 139,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data = [['Sunny', 'Hot', 'High', 'Weak', 'No'],\n",
        "       ['Sunny', 'Hot', 'High', 'Strong', 'No'],\n",
        "       ['Overcast', 'Hot', 'High', 'Weak', 'Yes'],\n",
        "       ['Rain', 'Mild', 'High', 'Weak', 'Yes'],\n",
        "       ['Rain', 'Cool', 'Normal', 'Weak', 'Yes'],\n",
        "       ['Rain', 'Cool', 'Normal', 'Strong', 'No'],\n",
        "       ['Overcast', 'Cool', 'Normal', 'Strong', 'Yes'],\n",
        "       ['Sunny', 'Mild', 'High', 'Weak', 'No'],\n",
        "       ['Sunny', 'Cool', 'Normal', 'Weak', 'Yes'],\n",
        "       ['Rain', 'Mild', 'Normal', 'Weak', 'Yes'],\n",
        "       ['Sunny', 'Mild', 'Normal', 'Strong', 'Yes'],\n",
        "       ['Overcast', 'Mild', 'High', 'Strong', 'Yes'],\n",
        "       ['Overcast', 'Hot', 'Normal', 'Weak', 'Yes'],\n",
        "       ['Rain', 'Mild', 'High', 'Strong', 'No']]\n",
        "colums = ['Outlook', 'Temperature', 'Humidity', 'Wind', 'Play']\n",
        "dataset = pd.DataFrame(data, columns = colums)\n",
        "dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3a775994",
      "metadata": {
        "id": "3a775994"
      },
      "source": [
        "We provide the class TreeNode that represents a node in the decision tree. Each node has a feature with the corresponding splitting value, and two children nodes. The class TreeBase provides the basic structure of a decision tree, and the class DecisionTree inherits from TreeBase, which you need to complete the missing parts."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 140,
      "id": "d100ad77",
      "metadata": {
        "id": "d100ad77"
      },
      "outputs": [],
      "source": [
        "class TreeNode(object): # Do not modify this class\n",
        "    '''\n",
        "    A node class for a decision tree.\n",
        "    '''\n",
        "    def __init__(self, feature=None, value=None, left=None, right=None, label=None):\n",
        "        self.feature = feature # feature to split on\n",
        "        self.value = value # value used for splitting\n",
        "        self.left = left # left child\n",
        "        self.right = right # right child\n",
        "        self.label = label # label for the node"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "28c197fc",
      "metadata": {
        "id": "28c197fc"
      },
      "source": [
        "The class TreeBase give you the overall structure of building a decision tree recursively (`build_tree` function), which following these essential steps:\n",
        "- Create a root of the tree, and split the dataset based on the feature that gives the most information gain.\n",
        "- Recursively build the left and right subtrees.\n",
        "- Stop the recursion when the stopping criteria are met."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 141,
      "id": "6c3a12c5",
      "metadata": {
        "id": "6c3a12c5"
      },
      "outputs": [],
      "source": [
        "class TreeBase(object): # Do not modify this class\n",
        "    def __init__(self, data, label, max_depth=5):\n",
        "        '''\n",
        "        Constructor\n",
        "        Parameters:\n",
        "            data: DataFrame, the data for the tree\n",
        "            label: str, the label of the target\n",
        "            max_depth: int, the maximum depth of the tree\n",
        "        '''\n",
        "        self.data = data\n",
        "        self.root = None\n",
        "        self.max_depth = max_depth\n",
        "        self.label = label\n",
        "        self.features = data.columns.drop(label)\n",
        "\n",
        "    def select_best_feature(self, data, features):\n",
        "        '''\n",
        "        Select the feature with the highest information gain\n",
        "        Parameters:\n",
        "            data: DataFrame\n",
        "            features: list of features\n",
        "        Returns:\n",
        "            best_feature: str\n",
        "            best_value: str\n",
        "        '''\n",
        "        best_gain = 0\n",
        "\n",
        "        for feature in features: #Iterate over all features\n",
        "            values = data[feature].unique() #Get all unique values of the feature\n",
        "            for value in values: #Iterate over all values\n",
        "                gain = self.information_gain(data, feature, value) #Calculate the information gain\n",
        "                if gain > best_gain:\n",
        "                    best_gain = gain\n",
        "                    best_feature = feature\n",
        "                    best_value = value\n",
        "\n",
        "        return best_feature, best_value\n",
        "\n",
        "    def entropy(self, data):\n",
        "        raise NotImplementedError\n",
        "\n",
        "    def information_gain(self, data, feature, value):\n",
        "        raise NotImplementedError\n",
        "\n",
        "    def predict(self, data_point):\n",
        "        '''\n",
        "        Predict the label for a single instance\n",
        "        Parameters:\n",
        "            data_point: pandas Series, with keys being the feature names\n",
        "        Returns:\n",
        "            label: the label of the instance\n",
        "        '''\n",
        "        node = self.root\n",
        "        label = None\n",
        "        while True:\n",
        "            if node.label is not None: #Leaf node\n",
        "                label = node.label\n",
        "                break\n",
        "            if type(node.value) == str: #Categorical feature\n",
        "                go_left = data_point[node.feature] == node.value\n",
        "            else: #Numerical feature\n",
        "                go_left = data_point[node.feature] < node.value\n",
        "\n",
        "            if go_left:\n",
        "                node = node.left\n",
        "            else:\n",
        "                node = node.right\n",
        "        return label\n",
        "\n",
        "    def fit(self):\n",
        "        self.root = self.build_tree(TreeNode(), self.data, self.features, 0) #Build the tree\n",
        "\n",
        "    def build_tree(self, node, data, features, depth):\n",
        "        '''\n",
        "        Recursively build the decision tree\n",
        "        Parameters:\n",
        "            node: TreeNode, current node to be split\n",
        "            data: DataFrame, the data for the tree\n",
        "            features: list of features\n",
        "            depth: int, the current depth of the tree\n",
        "        Returns:\n",
        "            node: TreeNode, the root of the built tree\n",
        "        '''\n",
        "\n",
        "        #Stop if the entropy is 0, or the depth >= max_depth, or all data points has the same feature value.\n",
        "        stop = np.isclose(self.entropy(data), 0) or \\\n",
        "                 depth >= self.max_depth or \\\n",
        "                 (data.values[0] == data.values).all()\n",
        "        if stop:\n",
        "            node = TreeNode()\n",
        "            node.label = data[self.label].mode()[0] #Get the most common label, only set label for leaf nodes\n",
        "            return node\n",
        "\n",
        "        feature, value = self.select_best_feature(data, features)\n",
        "        node = TreeNode(feature=feature, value=value)\n",
        "        if type(value) == str: #Categorical feature\n",
        "            left_data, right_data = data[data[feature] == value], data[data[feature] != value]\n",
        "        else: #Numerical feature\n",
        "            left_data, right_data = data[data[feature] < value], data[data[feature] >= value]\n",
        "\n",
        "        node.left = self.build_tree(node.left, left_data, features, depth + 1)\n",
        "        node.right = self.build_tree(node.right, right_data, features, depth + 1)\n",
        "        return node\n",
        "\n",
        "    def print_tree(self):\n",
        "        '''\n",
        "        Print the tree\n",
        "        Parameters:\n",
        "            node: TreeNode, the current node\n",
        "            depth: int, the current depth of the tree\n",
        "        '''\n",
        "        self._print_tree(self.root, 0)\n",
        "\n",
        "    def _print_tree(self, node, depth):\n",
        "        '''\n",
        "        Recursively print the tree\n",
        "        Parameters:\n",
        "            node: TreeNode, the current node\n",
        "            depth: int, the current depth of the tree\n",
        "        '''\n",
        "        if node is None:\n",
        "            return\n",
        "        if node.label is not None:\n",
        "            print(\" \" * depth, node.label)\n",
        "        else:\n",
        "            if type(node.value) == str:\n",
        "                print(\" \" * depth, node.feature, \"=\", node.value)\n",
        "            else:\n",
        "                print(\" \" * depth, node.feature, \"<\", node.value)\n",
        "            self._print_tree(node.left, depth + 1)\n",
        "            self._print_tree(node.right, depth + 1)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b978a829",
      "metadata": {
        "id": "b978a829"
      },
      "source": [
        "You will need to **provide the missing code** in the DecisionTree class below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 157,
      "id": "332fb2d6",
      "metadata": {
        "id": "332fb2d6"
      },
      "outputs": [],
      "source": [
        "class DecisionTree(TreeBase):\n",
        "    '''\n",
        "    Binary decision tree class, inherits from TreeBase\n",
        "    '''\n",
        "    def __init__(self, data, label, max_depth=5):\n",
        "        super(DecisionTree, self).__init__(data, label, max_depth)\n",
        "\n",
        "    def entropy(self, data):\n",
        "        '''\n",
        "        Calculate the entropy of the data\n",
        "        Parameters:\n",
        "            data: DataFrame\n",
        "        Returns:\n",
        "            the entropy of the data\n",
        "        '''\n",
        "        # TODO: ...WRITE YOUR CODE HERE...\n",
        "\n",
        "        # entropy (h) = sum for all x in data: -p(x)log(p(x))\n",
        "\n",
        "        # get relevant column (Play, last column)\n",
        "        plays = data.iloc[:, -1:]\n",
        "\n",
        "        # count number of \"yes\" vs \"no\" (get frequency of all values)\n",
        "        play_counts = plays.value_counts()\n",
        "        \n",
        "        # calculate entropy, h\n",
        "        calculated_entropy = 0\n",
        "        for play_count in play_counts.values:\n",
        "            probability = play_count / len(plays)\n",
        "            if probability > 0:\n",
        "                calculated_entropy -= probability * np.log2(probability)\n",
        "\n",
        "        return calculated_entropy\n",
        "\n",
        "\n",
        "    def information_gain(self, data, feature, value):\n",
        "        '''\n",
        "        Calculate the information gain\n",
        "        Parameters:\n",
        "            data: DataFrame\n",
        "            feature: the feature to split\n",
        "            vavlue: the value of the feature\n",
        "        Returns:\n",
        "            the information gain\n",
        "\n",
        "        '''\n",
        "        # TODO: ...WRITE YOUR CODE HERE...\n",
        "\n",
        "        entropy_total = self.entropy(data)\n",
        "\n",
        "        # split data\n",
        "        data_left = data[data[feature] <= value]\n",
        "        data_right = data[data[feature] > value]\n",
        "\n",
        "        # get split entropies\n",
        "        entropy_left = self.entropy(data_left)\n",
        "        entropy_right = self.entropy(data_right)\n",
        "\n",
        "        # get weights for split entropies\n",
        "        weight_left = len(data_left) / len(data)\n",
        "        weight_right = len(data_right) / len(data)\n",
        "\n",
        "        # combine split entropies by weights to get net weighted entropy\n",
        "        entropy_weighted = (weight_left * entropy_left) + (weight_right * entropy_right)\n",
        "\n",
        "        # get information gained by splitting data on feature by value\n",
        "        ig = entropy_total - entropy_weighted\n",
        "\n",
        "        return ig"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ff2934cc",
      "metadata": {
        "id": "ff2934cc"
      },
      "source": [
        "We provide the code to test the decision tree on the tennis dataset. You can add more tests to check your implementation. We will not grade your additional tests, but we encourage you to do so to ensure your implementation is correct."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 158,
      "id": "c60d121e",
      "metadata": {
        "id": "c60d121e"
      },
      "outputs": [],
      "source": [
        "dt = DecisionTree(dataset, 'Play', 5)\n",
        "data_test1 = dataset.iloc[:6]\n",
        "assert np.isclose(dt.entropy(data_test1), 1.0) # Test entropy implementation\n",
        "dt.fit() # Test build the tree and make sure there is no error"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 159,
      "id": "f595d461",
      "metadata": {
        "id": "f595d461"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Outlook = Overcast\n",
            "  Yes\n",
            "  Humidity = High\n",
            "   Outlook = Rain\n",
            "    Wind = Strong\n",
            "     No\n",
            "     Yes\n",
            "    No\n",
            "   Wind = Strong\n",
            "    Outlook = Rain\n",
            "     No\n",
            "     Yes\n",
            "    Yes\n"
          ]
        }
      ],
      "source": [
        "dt.print_tree() # Print the tree"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 160,
      "id": "3af9bf33",
      "metadata": {
        "id": "3af9bf33"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Outlook        Sunny\n",
            "Temperature      Hot\n",
            "Humidity        High\n",
            "Wind            Weak\n",
            "Play              No\n",
            "Name: 0, dtype: object\n",
            "----------\n",
            "prediction: No\n"
          ]
        }
      ],
      "source": [
        "sample = dataset.iloc[0]\n",
        "print(sample)\n",
        "print('----------')\n",
        "print('prediction:', dt.predict(sample)) # Test predict function"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "65f3af6c",
      "metadata": {
        "id": "65f3af6c"
      },
      "source": [
        "Next, you will need to provide the code for evaluating the tree. The function take a tree model, and a dataset then output the accuracy of the decision tree on the dataset. The accuracy is defined as the number of correct predictions divided by the total number of predictions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 161,
      "id": "4f1ed42a",
      "metadata": {
        "id": "4f1ed42a"
      },
      "outputs": [],
      "source": [
        "def evaluate(dt: TreeBase, dataset: pd.DataFrame):\n",
        "    '''\n",
        "    Evaluate the decision tree\n",
        "    Parameters:\n",
        "        dt: DecisionTree\n",
        "        dataset: DataFrame\n",
        "    Returns:\n",
        "        accuracy: the accuracy of the model on the dataset\n",
        "    '''\n",
        "    # TODO: ...WRITE YOUR CODE HERE...\n",
        "\n",
        "    # values we should get by running features through the model\n",
        "    expected_values = dataset.iloc[:, -1:]\n",
        "\n",
        "    # run input data through model\n",
        "    inputs = dataset.iloc[:, :-1]\n",
        "    correct_predictions = 0\n",
        "    for i in range(len(expected_values)):\n",
        "        input_feautures = inputs.iloc[i]\n",
        "        predicted_value = dt.predict(input_feautures)\n",
        "\n",
        "        # compare predicted value with expected value\n",
        "        if predicted_value == expected_values.iloc[i].values[0]:\n",
        "            correct_predictions += 1\n",
        "\n",
        "    return correct_predictions / len(expected_values)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 162,
      "id": "e57e1088",
      "metadata": {
        "id": "e57e1088"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "accuracy: 1.0\n"
          ]
        }
      ],
      "source": [
        "# test evaluate function\n",
        "print('accuracy:', evaluate(dt, dataset)) # Test evaluate function"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b27d4480",
      "metadata": {
        "id": "b27d4480"
      },
      "source": [
        "# Part II: The effect of tree complexity on the performance\n",
        "\n",
        "Things to do in this part:\n",
        "1. Update your DecisionTree class to handle numerical features.\n",
        "1. Provide the code for training and evaluating the decision tree with various tree depths.\n",
        "1. Plot the train and test accuracy.\n",
        "1. Answer discussion questions.\n",
        "\n",
        "\n",
        "Unlike the tennis dataset, which contains only categorical data, this part will involve working with numerical data. If you haven't already, modify your DecisionTree code to handle both categorical and numerical features. The code below generates a dataset of 1,000 samples with binary class labels. As in the previous section, we will store the dataset in a pandas DataFrame."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 163,
      "id": "f5754a84",
      "metadata": {
        "id": "f5754a84",
        "outputId": "0936b44b-daaa-4291-d297-00a10c8ae3ec"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>feature_0</th>\n",
              "      <th>feature_1</th>\n",
              "      <th>feature_2</th>\n",
              "      <th>feature_3</th>\n",
              "      <th>feature_4</th>\n",
              "      <th>feature_5</th>\n",
              "      <th>feature_6</th>\n",
              "      <th>feature_7</th>\n",
              "      <th>feature_8</th>\n",
              "      <th>feature_9</th>\n",
              "      <th>...</th>\n",
              "      <th>feature_11</th>\n",
              "      <th>feature_12</th>\n",
              "      <th>feature_13</th>\n",
              "      <th>feature_14</th>\n",
              "      <th>feature_15</th>\n",
              "      <th>feature_16</th>\n",
              "      <th>feature_17</th>\n",
              "      <th>feature_18</th>\n",
              "      <th>feature_19</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-0.272427</td>\n",
              "      <td>-0.029398</td>\n",
              "      <td>-0.636882</td>\n",
              "      <td>1.520092</td>\n",
              "      <td>-0.239273</td>\n",
              "      <td>1.569953</td>\n",
              "      <td>0.207139</td>\n",
              "      <td>-0.751345</td>\n",
              "      <td>-0.310397</td>\n",
              "      <td>-0.693804</td>\n",
              "      <td>...</td>\n",
              "      <td>-1.482397</td>\n",
              "      <td>0.884843</td>\n",
              "      <td>0.131119</td>\n",
              "      <td>-1.607711</td>\n",
              "      <td>2.051247</td>\n",
              "      <td>-1.954593</td>\n",
              "      <td>-0.099314</td>\n",
              "      <td>-0.527984</td>\n",
              "      <td>-1.569390</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.603702</td>\n",
              "      <td>-0.758917</td>\n",
              "      <td>-1.073091</td>\n",
              "      <td>0.405850</td>\n",
              "      <td>-1.308684</td>\n",
              "      <td>-0.445018</td>\n",
              "      <td>-0.848905</td>\n",
              "      <td>0.906784</td>\n",
              "      <td>0.913607</td>\n",
              "      <td>0.690701</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.866448</td>\n",
              "      <td>-0.797485</td>\n",
              "      <td>-0.069852</td>\n",
              "      <td>2.329718</td>\n",
              "      <td>0.380520</td>\n",
              "      <td>0.459637</td>\n",
              "      <td>0.142688</td>\n",
              "      <td>-0.214368</td>\n",
              "      <td>-0.125819</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.725821</td>\n",
              "      <td>-0.498031</td>\n",
              "      <td>0.551256</td>\n",
              "      <td>0.612412</td>\n",
              "      <td>1.700972</td>\n",
              "      <td>0.462312</td>\n",
              "      <td>-1.139286</td>\n",
              "      <td>-0.370698</td>\n",
              "      <td>-0.271115</td>\n",
              "      <td>0.305701</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.233880</td>\n",
              "      <td>-0.201946</td>\n",
              "      <td>0.550813</td>\n",
              "      <td>0.721858</td>\n",
              "      <td>-1.250026</td>\n",
              "      <td>0.349293</td>\n",
              "      <td>0.551437</td>\n",
              "      <td>-0.387667</td>\n",
              "      <td>0.923033</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.946618</td>\n",
              "      <td>0.029895</td>\n",
              "      <td>-0.335516</td>\n",
              "      <td>-0.216419</td>\n",
              "      <td>-1.119250</td>\n",
              "      <td>-0.057604</td>\n",
              "      <td>0.255977</td>\n",
              "      <td>-0.363176</td>\n",
              "      <td>0.369926</td>\n",
              "      <td>-0.270270</td>\n",
              "      <td>...</td>\n",
              "      <td>0.915824</td>\n",
              "      <td>-0.778309</td>\n",
              "      <td>-0.136422</td>\n",
              "      <td>-0.011394</td>\n",
              "      <td>-0.443429</td>\n",
              "      <td>0.934655</td>\n",
              "      <td>1.612868</td>\n",
              "      <td>0.033045</td>\n",
              "      <td>-0.140276</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-0.249894</td>\n",
              "      <td>-0.725025</td>\n",
              "      <td>-0.426571</td>\n",
              "      <td>-0.404639</td>\n",
              "      <td>1.355805</td>\n",
              "      <td>0.683565</td>\n",
              "      <td>-0.389404</td>\n",
              "      <td>0.558695</td>\n",
              "      <td>0.280236</td>\n",
              "      <td>0.384209</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.907327</td>\n",
              "      <td>-0.892773</td>\n",
              "      <td>-1.224387</td>\n",
              "      <td>1.039595</td>\n",
              "      <td>1.734042</td>\n",
              "      <td>0.292149</td>\n",
              "      <td>0.107760</td>\n",
              "      <td>-0.567810</td>\n",
              "      <td>-1.197958</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 21 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   feature_0  feature_1  feature_2  feature_3  feature_4  feature_5  \\\n",
              "0  -0.272427  -0.029398  -0.636882   1.520092  -0.239273   1.569953   \n",
              "1   1.603702  -0.758917  -1.073091   0.405850  -1.308684  -0.445018   \n",
              "2   0.725821  -0.498031   0.551256   0.612412   1.700972   0.462312   \n",
              "3   0.946618   0.029895  -0.335516  -0.216419  -1.119250  -0.057604   \n",
              "4  -0.249894  -0.725025  -0.426571  -0.404639   1.355805   0.683565   \n",
              "\n",
              "   feature_6  feature_7  feature_8  feature_9  ...  feature_11  feature_12  \\\n",
              "0   0.207139  -0.751345  -0.310397  -0.693804  ...   -1.482397    0.884843   \n",
              "1  -0.848905   0.906784   0.913607   0.690701  ...   -0.866448   -0.797485   \n",
              "2  -1.139286  -0.370698  -0.271115   0.305701  ...   -0.233880   -0.201946   \n",
              "3   0.255977  -0.363176   0.369926  -0.270270  ...    0.915824   -0.778309   \n",
              "4  -0.389404   0.558695   0.280236   0.384209  ...   -0.907327   -0.892773   \n",
              "\n",
              "   feature_13  feature_14  feature_15  feature_16  feature_17  feature_18  \\\n",
              "0    0.131119   -1.607711    2.051247   -1.954593   -0.099314   -0.527984   \n",
              "1   -0.069852    2.329718    0.380520    0.459637    0.142688   -0.214368   \n",
              "2    0.550813    0.721858   -1.250026    0.349293    0.551437   -0.387667   \n",
              "3   -0.136422   -0.011394   -0.443429    0.934655    1.612868    0.033045   \n",
              "4   -1.224387    1.039595    1.734042    0.292149    0.107760   -0.567810   \n",
              "\n",
              "   feature_19  label  \n",
              "0   -1.569390    1.0  \n",
              "1   -0.125819    0.0  \n",
              "2    0.923033    1.0  \n",
              "3   -0.140276    1.0  \n",
              "4   -1.197958    1.0  \n",
              "\n",
              "[5 rows x 21 columns]"
            ]
          },
          "execution_count": 163,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Don't modify this cell, we will use this code to generate synthetic data\n",
        "X, y = make_classification(n_samples=1000, n_features=20, n_classes=2, random_state=42)\n",
        "# Split data into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.7, random_state=42)\n",
        "# Create a pandas DataFrame for the train/test data\n",
        "columns = ['feature_' + str(i) for i in range(X_train.shape[1])] + ['label']\n",
        "df_train = pd.DataFrame(np.column_stack((X_train, y_train)), columns=columns)\n",
        "df_test = pd.DataFrame(np.column_stack((X_test, y_test)), columns=columns)\n",
        "df_train.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 164,
      "id": "5c2b6c03",
      "metadata": {
        "id": "5c2b6c03"
      },
      "outputs": [],
      "source": [
        "# test fitting the decision tree\n",
        "dt = DecisionTree(df_train, 'label', 0)\n",
        "dt.fit()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 165,
      "id": "ae783b7b",
      "metadata": {
        "id": "ae783b7b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train accuracy: 0.5066666666666667\n",
            "Test accuracy: 0.49714285714285716\n"
          ]
        }
      ],
      "source": [
        "# test evaluate function\n",
        "train_acc_value, test_acc_value = evaluate(dt, df_train), evaluate(dt, df_test)\n",
        "print('Train accuracy:', train_acc_value)\n",
        "print('Test accuracy:', test_acc_value)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d8f8e40c",
      "metadata": {
        "id": "d8f8e40c"
      },
      "source": [
        "Now, we will try to understand the effect of the complexity of the tree on the performance. We will use the depth of the tree as a measure of complexity. We will train the decision tree with different depths and evaluate the performance on the training and testing datasets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 168,
      "id": "8bd3cf21",
      "metadata": {
        "id": "8bd3cf21"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tree 0 done\n",
            "tree 1 done\n",
            "tree 2 done\n",
            "tree 3 done\n"
          ]
        }
      ],
      "source": [
        "max_depth = 3 #you can vary the depth, the larger the depth, the longer it will take to train. This is just our recommended number\n",
        "train_acc, test_acc = [], [] #store the training/test accuracy for each tree depth\n",
        "for tree_depth in range(max_depth + 1):\n",
        "    # TODO: ...WRITE YOUR CODE HERE...\n",
        "    # Fit the decision tree for each tree depth and evaluate the accuracy of on the training and test data\n",
        "\n",
        "    tree = DecisionTree(df_train, 'label', tree_depth)\n",
        "    tree.fit()\n",
        "\n",
        "    train_acc.append(evaluate(tree, df_train))\n",
        "    test_acc.append(evaluate(tree, df_test))\n",
        "\n",
        "    print(\"tree\", tree_depth, \"done\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "18ec1e38",
      "metadata": {
        "id": "18ec1e38"
      },
      "source": [
        "Plot the train and test accuracy with the corresponding depth of the tree. The x axis should be the maximum depth of the tree, and the y axis should be the accuracy. You should have two plots, one for the training accuracy and one for the testing accuracy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 169,
      "id": "11ed2264",
      "metadata": {
        "id": "11ed2264"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# TODO: ...WRITE YOUR CODE HERE...\n",
        "# write the code to plot the train and test accuracy for each tree depth\n",
        "\n",
        "plt.plot(range(len(train_acc)), train_acc, 'r')\n",
        "plt.plot(range(len(test_acc)), test_acc, 'b')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e9cfdb51",
      "metadata": {
        "id": "e9cfdb51"
      },
      "source": [
        "#### Discussion questions:\n",
        "\n",
        "What do you observe from the plot? Discuss your findings based on the train and test accuracy when increasing the depth of the tree."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "639fd610",
      "metadata": {
        "id": "639fd610"
      },
      "source": [
        "<font color='blue'>\n",
        "    TODO: replace this cell with your answer\n",
        "</font>\n",
        "\n",
        "The model does not increase very much after an initial jump. And that initial jump is only because it goes from making no decisions based on the data to actually interpreting the features' impact on the outcome. Increasing complexity substantially increases training times, but the return on the investement is marginal for the given data. It improves more against the training data than the test data as well. The extra depth can result in fitting the training data too much and simply memorizing the dataset rather than learning the patterns."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c0e7a706",
      "metadata": {
        "id": "c0e7a706"
      },
      "source": [
        "## Feedback\n",
        "\n",
        "Please provide us with some feedback on how long each section or this homework overall took you. Any other feedback is also welcomed.\n",
        "\n",
        "The analytical portion took an incredibly long time for me to complete. I didn't keep track, but definitely on the order of 10 hours, quite possibly more. So it was definitely jarring when I finished the practicum much quicker, though it felt like it took a reasonable amount of time still."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dcefedb6",
      "metadata": {
        "id": "dcefedb6"
      },
      "source": [
        "## Submit\n",
        "Great work! You're all done.\n",
        "\n",
        "Make sure to submit this Python notebook. See the homework writeup for directions."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
