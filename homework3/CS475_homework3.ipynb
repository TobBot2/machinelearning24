{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IQmp-ad0hZsO"
      },
      "source": [
        "# **Homework 3 Practicum**\n",
        "# Version 1.0 (October 4, 2024)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "slq1QivyhZsP"
      },
      "source": [
        "<font color='blue'> TODO:</font> Trevor Black (tblack20)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FV22tFvMhZsP"
      },
      "source": [
        "Instructions:\n",
        "This notebook has two parts:\n",
        "\n",
        "Part 1: Implement Perceptron using Rosenblatt's Algorithm.\n",
        "\n",
        "Part 2: Implement SVM using quadratic solver.\n",
        "\n",
        "Please answer all questions in this notebook (you will see <font color='blue'>TODO</font> annotations for where to include your answers). At the beginning of each part, we will bullet the expected deliverables for you to complete.\n",
        "\n",
        "Please <font color='blue'>make a copy of this notebook in your own drive</font> before you make any edits. You can do so through File -> Save a copy in Drive\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "dq6iPbgVhZsP"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import  StandardScaler\n",
        "from sklearn.datasets import make_blobs,make_moons\n",
        "from sklearn.metrics import confusion_matrix, precision_score, recall_score\n",
        "\n",
        "np.random.seed(42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "b-odGeZdhZsQ"
      },
      "source": [
        "\n",
        "# **PART I: Perceptron**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "aotAcGOehZsR"
      },
      "source": [
        "Things to do in this part:\n",
        "1. Implement fit and predict methods of Perceptron class\n",
        "2. Answer the questions\n",
        "\n",
        "\n",
        "In this section, we explore the implementation and evaluation of a Perceptron, a foundational algorithm in machine learning for binary classification tasks. The Perceptron model mimics the functioning of a neuron in the human brain, making decisions based on linear combinations of input features.\n",
        "\n",
        "We will generate synthetic datasets using the make_blobs function, varying the standard deviation of the clusters to observe how this affects the Perceptron's performance. The notebook covers:\n",
        "\n",
        "Dataset Generation: Creating synthetic datasets with two classes using varying standard deviations.\n",
        "\n",
        "Data Preprocessing: Splitting the dataset into training and test sets and applying feature scaling for optimal model performance.\n",
        "\n",
        "Model Training: Training the Perceptron on the scaled training data.\n",
        "Evaluation: Making predictions on the test set and calculating the accuracy of the model.\n",
        "\n",
        "Visualization: Plotting decision boundaries to visually assess how well the Perceptron separates the two classes.\n",
        "\n",
        "By the end of this notebook, you'll gain insights into the behavior of the Perceptron under different conditions and understand its strengths and limitations in handling linearly separable data.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QxBa4sA4n1F8",
        "tags": []
      },
      "outputs": [],
      "source": [
        "class Perceptron:\n",
        "    def __init__(self,  n_iterations=1000):\n",
        "        \"\"\"\n",
        "        Initialize the Perceptron model.\n",
        "\n",
        "        Parameters:\n",
        "        n_iterations (int): Number of training iterations.\n",
        "        \"\"\"\n",
        "        self.n_iterations = n_iterations\n",
        "        self.beta0 = 0  # bias term\n",
        "        self.beta = None  # weights\n",
        "\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        \"\"\"\n",
        "        Fit the Perceptron model to the training data.\n",
        "        Note: Save self.beta0 and self.beta every 100 iterations for plotting decision boundaries.\n",
        "\n",
        "        Parameters:\n",
        "        X (numpy.ndarray): Training data.\n",
        "        y (numpy.ndarray): Target labels.\n",
        "        \"\"\"\n",
        "        n_samples, n_features = X.shape\n",
        "        self.beta = np.zeros(n_features)\n",
        "\n",
        "        # TODO ...WRITE YOUR CODE HERE...\n",
        "        ...\n",
        "\n",
        "\n",
        "    def predict(self, X):\n",
        "        \"\"\"\n",
        "        Predict the labels for the given data.\n",
        "\n",
        "        Parameters:\n",
        "        X (numpy.ndarray): Input data.\n",
        "\n",
        "        Returns:\n",
        "        numpy.ndarray: Predicted labels.\n",
        "        \"\"\"\n",
        "        # TODO ...WRITE YOUR CODE HERE...\n",
        "        ...\n",
        "\n",
        "\n",
        "    def accuracy(self, y_true, y_pred):\n",
        "        \"\"\"\n",
        "        Calculate the accuracy of the predictions.\n",
        "\n",
        "        Parameters:\n",
        "        y_true (numpy.ndarray): True labels.\n",
        "        y_pred (numpy.ndarray): Predicted labels.\n",
        "\n",
        "        Returns:\n",
        "        float: Accuracy.\n",
        "        \"\"\"\n",
        "        accuracy = np.sum(y_true == y_pred) / len(y_true)\n",
        "        return accuracy\n",
        "\n",
        "    def plot_final_decision_boundary(self,X, y):\n",
        "      \"\"\"\n",
        "      Visualize the final decision boundary of the trained perceptron.\n",
        "\n",
        "      Parameters:\n",
        "      X (numpy.ndarray): Input data.\n",
        "      y (numpy.ndarray): Target labels.\n",
        "      \"\"\"\n",
        "      plt.figure(figsize=(8, 6))\n",
        "\n",
        "      # Plotting the data points\n",
        "      plt.scatter(X[:, 0], X[:, 1], c=y, cmap='coolwarm', edgecolors='k')\n",
        "\n",
        "      # Plotting the decision boundary\n",
        "      x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
        "      y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
        "      xx, yy = np.meshgrid(np.linspace(x_min, x_max, 100), np.linspace(y_min, y_max, 100))\n",
        "      Z = self.predict(np.c_[xx.ravel(), yy.ravel()])\n",
        "      Z = Z.reshape(xx.shape)\n",
        "\n",
        "      plt.contourf(xx, yy, Z, alpha=0.3, cmap='coolwarm')\n",
        "      plt.title('Decision Boundary of the Perceptron')\n",
        "      plt.xlabel('X')\n",
        "      plt.ylabel('y')\n",
        "      plt.xlim(xx.min(), xx.max())\n",
        "      plt.ylim(yy.min(), yy.max())\n",
        "      plt.axhline(0, color='black', lw=0.8)\n",
        "      plt.axvline(0, color='black', lw=0.8)\n",
        "      plt.grid()\n",
        "      plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "Qh2G9GZ1pnjf"
      },
      "outputs": [],
      "source": [
        "#The code iterates over a range of standard deviations to generate synthetic datasets and then trains and evaluates a Perceptron model on each dataset.\n",
        "for std_dev in range(1,8):\n",
        "  # Generate synthetic dataset\n",
        "  X, y = make_blobs(n_samples=100, centers=2 ,cluster_std=std_dev, random_state=42)\n",
        "\n",
        "  # Convert labels to -1 and 1\n",
        "  y = np.where(y == 0, -1, 1)\n",
        "\n",
        "  # Split the data into training and test sets\n",
        "  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "  # Feature scaling\n",
        "  scaler = StandardScaler()\n",
        "  X_train_scaled = scaler.fit_transform(X_train)\n",
        "  X_test_scaled = scaler.transform(X_test)\n",
        "  perceptron = Perceptron( n_iterations=1000)\n",
        "  perceptron.fit(X_train_scaled, y_train)\n",
        "\n",
        "  # Make predictions\n",
        "  predictions = perceptron.predict(X_test_scaled)\n",
        "  acc = perceptron.accuracy(predictions, y_test)\n",
        "\n",
        "  print(f\"std_dev={std_dev} Accuracy: {acc}\")\n",
        "  # Plot decision boundary\n",
        "  perceptron.plot_final_decision_boundary(X_train_scaled, y_train)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "L48a91AAXMc1"
      },
      "source": [
        "## **Question 1:** How does the perceptron adapt to different levels of data complexity? Also, discuss its performance and factors that can influence it?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "050okQR_-dRm"
      },
      "source": [
        "<font color='blue'>\n",
        "    TODO: replace this cell with your answer\n",
        "</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "zB_YQUzQsIwy"
      },
      "outputs": [],
      "source": [
        "def test_perceptron():\n",
        "  \"\"\"\n",
        "    Test the Perceptron implementation on a synthetic dataset.\n",
        "\n",
        "    This function generates a synthetic dataset, trains a Perceptron model,\n",
        "    evaluates its accuracy, and visualizes the decision boundaries.\n",
        "  \"\"\"\n",
        "  # Generate synthetic dataset\n",
        "  X, y = make_blobs(n_samples=100, centers=2 ,cluster_std=7.0, random_state=42)\n",
        "\n",
        "  # Convert labels to -1 and 1\n",
        "  y = np.where(y == 0, -1, 1)\n",
        "\n",
        "  # Split the data into training and test sets\n",
        "  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "  # Feature scaling\n",
        "  scaler = StandardScaler()\n",
        "  X_train_scaled = scaler.fit_transform(X_train)\n",
        "  X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "  for iter in range(100,1000,200):\n",
        "\n",
        "    # Create and train the Perceptron\n",
        "    perceptron = Perceptron(n_iterations=iter)\n",
        "    perceptron.fit(X_train_scaled, y_train)\n",
        "\n",
        "    # Make predictions\n",
        "    predictions = perceptron.predict(X_test_scaled)\n",
        "    acc = perceptron.accuracy(predictions, y_test)\n",
        "\n",
        "    print(f\"Iterations={iter}, Accuracy: {acc:.3f}\")\n",
        "    perceptron.plot_final_decision_boundary(X_train_scaled, y_train)\n",
        "\n",
        "test_perceptron()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "XGE8ZDS5hZsX"
      },
      "source": [
        "## **Question 2:**  Based on the visualizations, discuss the strengths and limitations of the Perceptron model in this context. What factors contribute to its effectiveness or ineffectiveness in separating the classes? Do you have any further suggestions ?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "X4keMKnmhZsX"
      },
      "source": [
        "<font color='blue'>\n",
        "    TODO: replace this cell with your answer\n",
        "</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "Sl0l66K8J96Q"
      },
      "source": [
        "\n",
        "# **PART II: SVM**\n",
        "Things to do in this part:\n",
        "1. Implement fit and predict methods of SVM class.\n",
        "1. Implement non-linear kernel.\n",
        "2. Answer the discusstion question.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "w8dw2gQjJcYy"
      },
      "source": [
        "In this part, you will implement the dual problem of the SVM optimization problem. As we have seen in class, the goal SVM is to find the optimal hyperplane that maximizes the margin and minimizes the misclassification, which can be formulated as the following (primal) optimization problem:\n",
        "\n",
        "$$\n",
        "\\begin{aligned}\n",
        "\\min _{\\vec{\\beta},\\beta_0} & \\frac{1}{2}\\|\\beta\\|^2+C \\sum_{i=1}^n \\xi_i \\\\\n",
        "\\text { s.t. } & y_i\\left(\\vec{x}_i^T \\vec{\\beta}+\\beta_0\\right) \\geq 1-\\xi_i, \\quad i=1, \\ldots, n \\\\\n",
        "& \\xi_i \\geq 0, \\quad i=1, \\ldots, n\n",
        "\\end{aligned}\n",
        "$$\n",
        "\n",
        "Instead of solving the primal problem, we can solve **dual** optimization problem instead:\n",
        "$$\n",
        "\\begin{aligned}\n",
        "\\max _\\alpha & \\sum_{i=1}^n \\alpha_i-\\frac{1}{2} \\sum_{i=1}^n \\sum_{j=1}^n \\alpha_i \\alpha_j y_i y_j \\vec{x}_i^T \\vec{x}_j \\\\\n",
        "\\text { s.t. } & 0 \\leq \\alpha_i \\leq C, \\quad i=1, \\ldots, n \\\\\n",
        "& \\sum_{i=1}^n \\alpha_i y_i=0\n",
        "\\end{aligned}\n",
        "$$\n",
        "\n",
        "You notice the above equations is a quadratic programming problem. Specifically, the quadratic programming problem can be written as:\n",
        "\n",
        "$$\n",
        "\\begin{array}{ll}\n",
        "\\operatorname{minimize} & (1 / 2) x^T P x+q^T x \\\\\n",
        "\\text { subject to } & G x \\preceq h \\\\\n",
        "& A x=b\n",
        "\\end{array}\n",
        "$$\n",
        "Please see the `cvxopt` documentation for more information: https://cvxopt.org/userguide/coneprog.html#quadratic-programming\n",
        "\n",
        "\n",
        "Your task is to specify the matrices/vectors $P$, $q$, $G$, $h$, $A$, and $b$ for the dual optimization problem of the SVM. You will specify those matrics/vectors in the `fit()` function:\n",
        "\n",
        "```python\n",
        "def fit(...):\n",
        "    ...\n",
        "    P = ...\n",
        "    q = ...\n",
        "    G = ...\n",
        "    h = ...\n",
        "    A = ...\n",
        "    b = ...\n",
        "    # solve QP problem\n",
        "    solution = cvxopt.solvers.qp(P, q, G, h, A, b)\n",
        "    ...\n",
        "```\n",
        "\n",
        " You don't need to provide the expression of these matrices/vector, but we highly recommend you write them down, this will help you to understand/resolve some of the issues you may encounter during the implementation.\n",
        "\n",
        "For the quadratic solver, we will use the `cvxopt` library to solve this quadratic programming problem.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Use the following command to install the `cvxopt` library:\n",
        "```bash\n",
        "!pip install cvxopt\n",
        "```\n",
        "or\n",
        "```bash\n",
        "!conda install -c conda-forge cvxopt\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "N554LrQNL_YO"
      },
      "outputs": [],
      "source": [
        "!pip install cvxopt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "4lo1SNJfIqg4"
      },
      "outputs": [],
      "source": [
        "import cvxopt # The optimization package for Quadratic Programming\n",
        "cvxopt.solvers.options['show_progress'] = False"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "TkSaPzLeLzlk"
      },
      "source": [
        "### Synthetic Dataset\n",
        "We use the moons dataset from `sklearn` to test/visualize the SVM implementation. We pro"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "IZpKE7TJL0G1"
      },
      "outputs": [],
      "source": [
        "X, y = make_moons (n_samples = 300, noise = 0.15, random_state = 10)\n",
        "y = y*2-1.0 # convert the labels from {0,1} to {-1, +1}\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,\n",
        "                                                    random_state=10)\n",
        "\n",
        "def plot_svm (clf, X, y, axes=[-2, 3, -2, 2]):\n",
        "    \"\"\"\n",
        "    Generate a simple plot of SVM including the decision boundary, margin, and its training data\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    clf: your classifier handle\n",
        "    X: feature matrix shape(m_samples, n_features)\n",
        "    y: label vector shape(m_samples, )\n",
        "    axes: (optional) the axes of the plot in format [xmin, xmax, ymin, ymax]\n",
        "    \"\"\"\n",
        "    # Create a mesh grid based on the provided axes (100 x 100 resolution)\n",
        "    x0s = np.linspace(axes[0], axes[1], 100)\n",
        "    x1s = np.linspace(axes[2], axes[3], 100)\n",
        "    x0, x1 = np.meshgrid(x0s,x1s) # create a mesh grid\n",
        "    X_mesh = np.c_[x0.ravel(), x1.ravel()] # convert all mesh points into 2-D points\n",
        "    y_pred = clf.predict(X_mesh).reshape(x0.shape) # predict then covert back to the 2-D\n",
        "    y_decision = clf.decision_function(X_mesh).reshape(x0.shape)\n",
        "\n",
        "    plt.figsize=(16, 9)\n",
        "    plt.plot(X[:, 0][y==-1], X[:, 1][y==-1], \"bo\", label=\"Class -1\")\n",
        "    plt.plot(X[:, 0][y==1], X[:, 1][y==1], \"go\", label=\"Class +1\")\n",
        "    # Plot out the support vectors (in red)\n",
        "    plt.scatter(clf.support_vectors_[:,0], clf.support_vectors_[:,1], s=80, c=\"r\", label=\"Support Vectors\")\n",
        "    # Plot decision boundary and margins\n",
        "    plt.contourf(x0,x1, y_pred, cmap = plt.cm.brg, alpha = 0.1)\n",
        "    plt.contourf(x0,x1, y_decision, cmap = plt.cm.brg, alpha = 0.2)\n",
        "    plt.contour(x0, x1, y_decision, colors='k',\n",
        "                 levels=[-1, 0, 1], alpha=0.5,\n",
        "                 linestyles=['--', '-', '--'])\n",
        "    plt.legend(loc=\"lower right\")\n",
        "    plt.axis(\"auto\")\n",
        "\n",
        "    plt.grid(True, which='both')\n",
        "    plt.xlabel(r\"$x_1$\", fontsize=20)\n",
        "    plt.ylabel(r\"$x_2$\", fontsize=20, rotation=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "Fgj-JJeLUjHn"
      },
      "source": [
        "You will need to provide the code for the kernel functions. To help you get started, the Linear Kernel (simply just a dot product) has been provided to you. You will need to provide the code for polynomial kernel and rbf kernel in the kernel trick question.\n",
        "These kernel functions will be called in the SVM class."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "WrSpFbvkMnfl"
      },
      "outputs": [],
      "source": [
        "# Linear Kernel\n",
        "def linear_kernel(u, v):\n",
        "    return np.dot(u, v)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I6TBNxQeMYPM",
        "tags": []
      },
      "outputs": [],
      "source": [
        "class MySVM(object):\n",
        "    \"\"\"The Implementation of the SVM class\"\"\"\n",
        "\n",
        "    def __init__(self, kernel=linear_kernel, C=1):\n",
        "        self.kernel = kernel # the kernel function used; this is a function and can be called\n",
        "        self.C = C # make sure to set this when instantiating this class; is C is None, your performance will be weird\n",
        "\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        \"\"\"\n",
        "        Train SVM based on the training set\n",
        "        Parameters\n",
        "        ----------\n",
        "        X: feature matrix shape(m_samples, n_features)\n",
        "        y: label vector shape(m_samples, )\n",
        "        \"\"\"\n",
        "        self.X = X\n",
        "        self.y = y\n",
        "\n",
        "        n_samples, _ = X.shape\n",
        "\n",
        "        # To speed up repeated applications of the kernel function, we store the kernel results in matrix K\n",
        "        # All pairs of points have the kernel function computed over them and the result stored in K\n",
        "        # K is indexed by indices in X, so K[i,j] = kernel_function(X[i], X[j])\n",
        "        K = np.zeros((n_samples, n_samples))\n",
        "        for i in range(n_samples):\n",
        "            for j in range(n_samples):\n",
        "                K[i,j] = self.kernel(X[i], X[j])\n",
        "\n",
        "\n",
        "\n",
        "        # This part requires some understanding of Quadratic Programming (QP)\n",
        "        # Below is the user's guide for the QP from CVXOPT\n",
        "        # http://cvxopt.org/userguide/coneprog.html#quadratic-programming\n",
        "\n",
        "\n",
        "        # TODO ...SPECIFY THE MATRICES/VECTORS FOR QP SOLVER...\n",
        "        # Use cvxopt.matrix to wrap a numpy matrix, e.g., P = cvxopt.matrix(your_numpy_matrix)\n",
        "\n",
        "        # P = cvxopt.matrix(...)\n",
        "        # q = cvxopt.matrix(...)\n",
        "        # G = cvxopt.matrix(...)\n",
        "        # h = cvxopt.matrix(...)\n",
        "        # A = cvxopt.matrix(...)\n",
        "        # b = cvxopt.matrix(...)\n",
        "\n",
        "        ...\n",
        "\n",
        "        # solve QP problem\n",
        "        solution = cvxopt.solvers.qp(P, q, G, h, A, b)\n",
        "\n",
        "        # Lagrange multipliers for each point in X\n",
        "        a = np.ravel(solution['x'])\n",
        "        # Support vectors have non zero lagrange multipliers\n",
        "        # sv is a boolean array\n",
        "        # sv[i] is True iff a[i] is non-zero\n",
        "        sv = a > 1e-5\n",
        "\n",
        "        self.support_vectors_ = X[sv]\n",
        "\n",
        "\n",
        "        self.a = a\n",
        "\n",
        "        # Compute beta_0 based on support vector\n",
        "        self.b0 = 0 #initalize beta_0\n",
        "        for i in range(len(a)):\n",
        "          if a[i] > 1e-5 and a[i] < self.C:\n",
        "            for j in range(len(X)):\n",
        "                self.b0 += a[j] * y[j] * K[i,j]\n",
        "\n",
        "            self.b0 += y[i] - self.b0\n",
        "        self.b0 /= len(self.support_vectors_)\n",
        "\n",
        "\n",
        "    def decision_function(self, X):\n",
        "        # TODO ...WRITE YOUR CODE HERE...\n",
        "        ...\n",
        "\n",
        "\n",
        "    def predict(self, X):\n",
        "        \"\"\"Predicts -1,+1 based on the sign of the decision function\"\"\"\n",
        "\n",
        "        return np.sign(self.decision_function(X))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "XTgfHpAINtjN"
      },
      "outputs": [],
      "source": [
        "def print_result(model, X_test, y_test):\n",
        "    prediction = model.predict(X_test)\n",
        "    print(\"confusion matrix:\", confusion_matrix(y_test, prediction))\n",
        "    print(\"recall:\",recall_score(y_test, prediction))\n",
        "    print(\"precision:\",precision_score(y_test, prediction))\n",
        "    plot_svm(model, X_train, y_train)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "etkLuc1vMsdU"
      },
      "outputs": [],
      "source": [
        "# Test and visualize your SVM model\n",
        "model = MySVM(C=8.1537, kernel=linear_kernel)\n",
        "model.fit(X_train, y_train)\n",
        "print_result(model, X_test, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "-DMK0IaOU-HO"
      },
      "source": [
        "# Kernel trick\n",
        "You would notice that the moon dataset is non-linearly separable, it is a good idea to use some non-linear kernels (kernel trick). You will need to provide the code for the polynomial kernel and rbf kernel below"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iXf3REwATrlL",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Polynomial Kernel (of degree up to and including p)\n",
        "def polynomial_kernel(u, v, p=3):\n",
        "    # TODO ...WRITE YOUR CODE HERE...\n",
        "    ...\n",
        "\n",
        "# Gaussian RBF Kernel\n",
        "def rbf_kernel(u, v, gamma=0.1):\n",
        "    # TODO ...WRITE YOUR CODE HERE...\n",
        "    ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "8-23hSKKN1qa"
      },
      "source": [
        "## **Question 3**: Try with different kernels and C values and see how the decision boundary changes. Provide **two** plots (one plot per kernel) with corresponding the non-linear kernel type and C value and discuss your finding.\n",
        "\n",
        "You might need to tune the C value for each kernel."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_1kweamRRk8X",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# TODO ...TRAIN/PLOT POLYNOMIAL KERNEL SVM...\n",
        "...\n",
        "# print_result(polynomial_model, X_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8Xet-oeEUI6I",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# TODO ...TRAIN/PLOT FOR RBF KERNEL SVM...\n",
        "...\n",
        "# print_result(rbf_model, X_test, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "8-7IxAeJyuYJ"
      },
      "source": [
        "<font color='blue'>\n",
        "    TODO: replace this cell with your answer\n",
        "</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3UyU_vfChZsd"
      },
      "source": [
        "## Feedback\n",
        "\n",
        "Please provide us with some feedback on how long each section or this homework overall took you. Any other feedback is also welcomed."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kVbMEfNuhZsd"
      },
      "source": [
        "## Submit\n",
        "Great work! You're all done.\n",
        "\n",
        "Make sure to submit this Python notebook. See the homework writeup for directions."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.5"
    },
    "otter": {
      "OK_FORMAT": true,
      "assignment_name": "hw03",
      "tests": {
        "Kernel": {
          "name": "Kernel",
          "points": null,
          "suites": [
            {
              "cases": [
                {
                  "code": ">>> np.testing.assert_equal(polynomial_kernel(np.array([1, 2]), np.array([3, 4]), p=2), 121)\n",
                  "failure_message": "polynomial test case 1",
                  "hidden": false,
                  "locked": false,
                  "points": 1,
                  "success_message": "polynomial test case 1"
                },
                {
                  "code": ">>> np.testing.assert_equal(polynomial_kernel(np.array([1, 3, 2, 2]), np.array([3, 4, 5, 1]), p=3), 19683)\n",
                  "failure_message": "polynomial test case 2",
                  "hidden": false,
                  "locked": false,
                  "points": 1,
                  "success_message": "polynomial test case 2"
                },
                {
                  "code": ">>> np.testing.assert_almost_equal(rbf_kernel(np.array([1, 2]), np.array([3, 4]), gamma=0.1), 0.44932896)\n",
                  "failure_message": "rbf test case 1",
                  "hidden": false,
                  "locked": false,
                  "points": 1,
                  "success_message": "rbf test case 1"
                },
                {
                  "code": ">>> np.testing.assert_almost_equal(rbf_kernel(np.array([1, 3, 2, 2]), np.array([3, 4, 5, 1]), gamma=0.3), 0.01110899653)\n",
                  "failure_message": "rbf test case 2",
                  "hidden": false,
                  "locked": false,
                  "points": 1,
                  "success_message": "rbf test case 2"
                }
              ],
              "scored": true,
              "setup": "",
              "teardown": "",
              "type": "doctest"
            }
          ]
        },
        "Perceptron": {
          "name": "Perceptron",
          "points": null,
          "suites": [
            {
              "cases": [
                {
                  "code": ">>> X, y = make_blobs(n_samples=100, centers=2, cluster_std=1.0, random_state=42)\n>>> y = np.where(y == 0, -1, 1)\n>>> X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n>>> scaler = StandardScaler()\n>>> X_train_scaled = scaler.fit_transform(X_train)\n>>> X_test_scaled = scaler.transform(X_test)\n>>> perceptron = Perceptron(n_iterations=1000)\n>>> perceptron.fit(X_train_scaled, y_train)\n>>> predictions = perceptron.predict(X_test_scaled)\n>>> acc = perceptron.accuracy(predictions, y_test)\n>>> assert np.equal(acc, 1.0)\n",
                  "failure_message": "Test the Perceptron with linearly separable data (dev=1.0).",
                  "hidden": false,
                  "locked": false,
                  "points": 3,
                  "success_message": "Test the Perceptron with linearly separable data (dev=1.0)."
                },
                {
                  "code": ">>> X, y = make_blobs(n_samples=100, centers=2, cluster_std=4.0, random_state=42)\n>>> y = np.where(y == 0, -1, 1)\n>>> X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n>>> scaler = StandardScaler()\n>>> X_train_scaled = scaler.fit_transform(X_train)\n>>> X_test_scaled = scaler.transform(X_test)\n>>> perceptron = Perceptron(n_iterations=1000)\n>>> perceptron.fit(X_train_scaled, y_train)\n>>> predictions = perceptron.predict(X_test_scaled)\n>>> acc = perceptron.accuracy(predictions, y_test)\n>>> assert np.equal(acc, 0.9)\n",
                  "failure_message": "Test the Perceptron with linearly separable data (dev=4.0).",
                  "hidden": false,
                  "locked": false,
                  "points": 3,
                  "success_message": "Test the Perceptron with linearly separable data (dev=4.0)."
                },
                {
                  "code": ">>> X, y = make_blobs(n_samples=100, centers=2, cluster_std=5.0, random_state=42)\n>>> y = np.where(y == 0, -1, 1)\n>>> X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n>>> scaler = StandardScaler()\n>>> X_train_scaled = scaler.fit_transform(X_train)\n>>> X_test_scaled = scaler.transform(X_test)\n>>> perceptron = Perceptron(n_iterations=1000)\n>>> perceptron.fit(X_train_scaled, y_train)\n>>> predictions = perceptron.predict(X_test_scaled)\n>>> acc = perceptron.accuracy(predictions, y_test)\n>>> assert np.equal(acc.round(3), 0.867)\n",
                  "failure_message": "Test the Perceptron with linearly separable data (dev=5.0).",
                  "hidden": false,
                  "locked": false,
                  "points": 3,
                  "success_message": "Test the Perceptron with linearly separable data (dev=5.0)."
                },
                {
                  "code": ">>> X, y = make_blobs(n_samples=100, centers=2, cluster_std=7.0, random_state=42)\n>>> y = np.where(y == 0, -1, 1)\n>>> X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n>>> scaler = StandardScaler()\n>>> X_train_scaled = scaler.fit_transform(X_train)\n>>> X_test_scaled = scaler.transform(X_test)\n>>> perceptron = Perceptron(n_iterations=1000)\n>>> perceptron.fit(X_train_scaled, y_train)\n>>> predictions = perceptron.predict(X_test_scaled)\n>>> acc = perceptron.accuracy(predictions, y_test)\n>>> assert np.equal(acc.round(3), 0.767)\n",
                  "failure_message": "Test the Perceptron with linearly separable data (dev=7.0).",
                  "hidden": false,
                  "locked": false,
                  "points": 3,
                  "success_message": "Test the Perceptron with linearly separable data (dev=7.0)."
                }
              ],
              "scored": true,
              "setup": "",
              "teardown": "",
              "type": "doctest"
            }
          ]
        },
        "svm_implementation": {
          "name": "svm_implementation",
          "points": null,
          "suites": [
            {
              "cases": [
                {
                  "code": ">>> X, y = make_moons(n_samples=4, noise=0.15, random_state=10)\n>>> y = y * 2 - 1.0\n>>> model = MySVM(C=10.5, kernel=linear_kernel)\n>>> model.fit(X, y)\n>>> np.testing.assert_array_almost_equal(model.a, [5.67261514, 10.49999996, 6.47249712, 1.6451123])\n",
                  "failure_message": "SVM test case 1 with linear kernel",
                  "hidden": false,
                  "locked": false,
                  "points": 4,
                  "success_message": "SVM test case 1 with linear kernel"
                },
                {
                  "code": ">>> X, y = make_moons(n_samples=20, noise=0.15, random_state=5)\n>>> y = y * 2 - 1.0\n>>> model = MySVM(C=10.5, kernel=linear_kernel)\n>>> model.fit(X, y)\n>>> desired = [10.5, 0.0, 0.0, 10.1606, 7.8719, 10.5, 10.5, 10.5, 0.0, 0.0, 0.0, 0.0, 0.0, 7.5324, 10.5, 0.0, 0.0, 0.0, 0.0, 0.0]\n>>> np.testing.assert_array_almost_equal(model.a, desired, decimal=3)\n",
                  "failure_message": "SVM test case 2 with linear kernel",
                  "hidden": false,
                  "locked": false,
                  "points": 3,
                  "success_message": "SVM test case 2 with linear kernel"
                },
                {
                  "code": ">>> X, y = make_moons(n_samples=4, noise=0.15, random_state=10)\n>>> y = y * 2 - 1.0\n>>> model = MySVM(C=10.5, kernel=linear_kernel)\n>>> model.fit(X, y)\n>>> X_test0, _ = make_moons(n_samples=4, noise=0.15, random_state=2)\n>>> np.testing.assert_array_almost_equal(model.predict(X_test0), np.array([1.0, 1.0, -1.0, -1.0]))\n",
                  "failure_message": "SVM test case 3 (prediction)",
                  "hidden": false,
                  "locked": false,
                  "points": 4,
                  "success_message": "SVM test case 3 (prediction)"
                },
                {
                  "code": ">>> X, y = make_moons(n_samples=10, noise=0.15, random_state=10)\n>>> y = y * 2 - 1.0\n>>> model = MySVM(C=10.5, kernel=linear_kernel)\n>>> model.fit(X, y)\n>>> X_test0, _ = make_moons(n_samples=10, noise=0.15, random_state=2)\n>>> desired = np.array([-1.0, -1.0, -1.0, 1.0, 1.0, -1.0, -1.0, 1.0, 1.0, 1.0])\n>>> np.testing.assert_array_almost_equal(model.predict(X_test0), desired)\n",
                  "failure_message": "SVM test case 4 (prediction)",
                  "hidden": false,
                  "locked": false,
                  "points": 3,
                  "success_message": "SVM test case 4 (prediction)"
                }
              ],
              "scored": true,
              "setup": "",
              "teardown": "",
              "type": "doctest"
            }
          ]
        }
      }
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
